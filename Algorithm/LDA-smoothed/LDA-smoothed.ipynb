{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: http://satomacoto.blogspot.jp/2009/12/pythonlda.html   \n",
    "Code in the reference is modified for Python 3  \n",
    "\n",
    "LDA ([Blei et al.](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf) Figure 1)  \n",
    "Variational Bayes EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,getopt\n",
    "from numpy import array,matrix,diag\n",
    "from scipy import sum,log,exp,mean,dot,ones,zeros\n",
    "from scipy.special import polygamma, gamma\n",
    "from scipy.linalg import norm\n",
    "from random import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/home/3928941380/Downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(emmax = 100, beta_estimate = 1):\n",
    "    # set parameters\n",
    "    k = 10 # of classes to assume\n",
    "    #emmax = 2 # of maximum VB-EM iteration (default 100)\n",
    "    demmax = 20 # of maximum VB-EM iteration for a document\n",
    "    epsilon = 0.0001 # A threshold to determine the whole convergence of the estimation\n",
    "    \n",
    "    # Train\n",
    "    train = open(\"train.txt\",'r').read()\n",
    "    alpha,phi, beta = ldamain(train, k, beta_estimate, emmax, demmax, epsilon)\n",
    "    \n",
    "    # Write\n",
    "    writer = open('output-alpha.txt','w')\n",
    "    writer.write(str(alpha.tolist()))\n",
    "    writer.close() \n",
    "    \n",
    "    writer = open('output-phi.txt','w')\n",
    "    writer.write(str(phi.tolist()))\n",
    "    writer.close()\n",
    "    \n",
    "    return alpha, phi, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ldamain(train, k, beta_estimate, emmax=100, demmax=20, epsilon=1.0e-4):\n",
    "    d = [ zip(*[ [int(x) for x in w.split(':')] for w in L.split()]) for L in train.split('\\n') if L ]\n",
    "    \n",
    "    data = []\n",
    "    for L in train.split(\"\\n\"):\n",
    "        if L == \"\":\n",
    "            continue\n",
    "\n",
    "        id_ = [int(w.split(\":\")[0]) for w in L.split(\" \")]\n",
    "        w_count = [int(w.split(\":\")[1]) for w in L.split(\" \")]\n",
    "\n",
    "        data.append([id_, w_count])\n",
    "    \n",
    "    return lda.train(data,k,beta_estimate,emmax,demmax, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class lda():\n",
    "    '''\n",
    "    Latent Dirichlet Allocation, standard model.\n",
    "    [alpha,phi] = lda.train(d,k,[emmax,demmax])\n",
    "    d      : data of documents\n",
    "    k      : # of classes to assume\n",
    "    emmax  : # of maximum VB-EM iteration (default 100)\n",
    "    demmax : # of maximum VB-EM iteration for a document (default 20)\n",
    "    '''\n",
    "    \n",
    "    @staticmethod\n",
    "    def train(d, k, beta_estimate, emmax=100, demmax=20, epsilon=1.0e-4):\n",
    "        '''\n",
    "        Latent Dirichlet Allocation, standard model.\n",
    "        [alpha,phi] = lda.train(d,k,[emmax,demmax])\n",
    "        d      : data of documents\n",
    "        k      : # of classes to assume\n",
    "        emmax  : # of maximum VB-EM iteration (default 100)\n",
    "        demmax : # of maximum VB-EM iteration for a document (default 20)\n",
    "        '''\n",
    "        \n",
    "        # # of documents\n",
    "        M = len(d)\n",
    "        # # of words\n",
    "        L = max(map(lambda x: max(x[0]), d)) + 1\n",
    "        \n",
    "        # initialize\n",
    "        beta = matrix(np.full((L, 1), 100, dtype=float) / L) # k x 1 matrix\n",
    "        phi = matrix(ones((k, L)) / L)\n",
    "        alpha = matrix(lda.normalize(sorted([random() for i in range(k)], reverse=True))).T\n",
    "        gammas = matrix(zeros((M, k)))\n",
    "        lik = 0\n",
    "        plik = lik\n",
    "        n_kv = matrix(np.random.rand(k, L))\n",
    "        phis = matrix(zeros((k, L)))\n",
    "        \n",
    "        #print ('number of documents (M)      = {0}'.format(M))\n",
    "        #print ('number of words (l)          = {0}'.format(L))\n",
    "        #print ('number of latent classes (k) = {0}'.format(k))\n",
    "        \n",
    "        for j in range(emmax):\n",
    "            if j % 10 == 0:\n",
    "                print ('iteration {0}/{1}..\\t'.format(j+1, emmax))\n",
    "            #vb-esstep\n",
    "            \n",
    "            nt_keep = []\n",
    "            for i in range(M):\n",
    "                gamma, q, nt, n_kv, xi_kv = lda.vbem(d[i], phi, alpha, beta, n_kv, demmax)\n",
    "                nt_keep.append(nt)\n",
    "                gammas[i,:] = gamma.T\n",
    "                phis = lda.accum_phi(phis,q,d[i], xi_kv)\n",
    "            #vb-mstep\n",
    "            alpha = lda.fpi_alpha(alpha, nt_keep)\n",
    "                    #alpha = lda.newton_alpha(gammas)\n",
    "            if beta_estimate == 1:\n",
    "                beta = lda.fpi_beta1(n_kv, beta)\n",
    "            else:\n",
    "                beta = lda.fpi_beta2(n_kv, beta)\n",
    "            phi = lda.mnormalize(phis,1)\n",
    "            #converge?\n",
    "#             lik = lda.lda_lik(d, phi, gammas)\n",
    "#             print ('log-likelihoood =', lik)\n",
    "#             if j > 1 and abs((lik - plik) / lik) < epsilon:\n",
    "#                 if j < 5:\n",
    "#                     return lda.train(d, k, emmax, demmax) # try again\n",
    "#                 print ('converged')\n",
    "#                 return alpha, phi\n",
    "#             plik = lik\n",
    "            \n",
    "        return alpha, phi, beta\n",
    "                \n",
    "\n",
    "    @staticmethod\n",
    "    def vbem(di, phi, alpha0, beta, n_kv, emmax=20):\n",
    "        '''\n",
    "        calculates a document and words posterior for a document d.\n",
    "        alpha  : Dirichlet posterior for a document d\n",
    "        q      : (Nd * K) matrix of word posterior over latent classes\n",
    "        di      : document data / here, only one sentence\n",
    "        phi   : \n",
    "        alpha0 : Dirichlet prior of alpha\n",
    "        emmax  : maximum # of VB-EM iteration.\n",
    "        '''\n",
    "        digamma = lambda x: polygamma(0,x)\n",
    "\n",
    "        Nd = len(di[0])\n",
    "        k = len(alpha0)\n",
    "        q = zeros((Nd, k))\n",
    "        nt = matrix(ones((1, k)) * Nd / k).T # initialize n_dk\n",
    "        pnt = nt\n",
    "        # xi_kv = n_kv + beta.T\n",
    "        \n",
    "        for j in range(emmax):\n",
    "            #vb-estep\n",
    "            q = matrix( matrix(exp(digamma((n_kv + beta.T)[:,di[0]])).T) * diag(exp(digamma(alpha0 + nt))[:,0]))\n",
    "            q = lda.mnormalize(q , 1)\n",
    "                    # q(z_d,i =k)\n",
    "                    # alpha0 + ntでよくわからないけど、alphaをアップデートしてるからe-step?\n",
    "                    # better to look at original C code\n",
    "                       #  ap[k]というのが、式のexpの分子部分相当\n",
    "                        #  それにphiをかけて最後に正規化している\n",
    "            #vb-mstep\n",
    "            nt =  q.T * matrix(di[1]).T\n",
    "                    # nt:  probably expectation part in Sato Equation(3.89), same as bottom in Sato p.75\n",
    "                    #  Sato p.75にあるように本来ならば文章中の一語ずつチェックするが、データセットには\n",
    "                    #  各単語ごとの出現回数しかないので、単語が登場するたびに足すのではなく、単語の出現回数×qをして\n",
    "                    #  足しあわせている\n",
    "                    # better to look at original C code\n",
    "            for k_index in range(k): \n",
    "                n_kv[k_index, di[0]]  = q.T[k_index, :]\n",
    "                # Sato p.77下の更新式だけど、ここでは全てのdに対しては更新しないで、vbem()に流れてきているものだけを更新 <-- ！！！！！！この方法で良いのか不明！！！！！\n",
    "\n",
    "            #converge?\n",
    "            if j > 1 and np.absolute((nt - pnt).sum()) / k < 3 :\n",
    "                break\n",
    "            pnt = nt.copy()\n",
    "            pnkv = n_kv.copy()\n",
    "\n",
    "        alpha = alpha0 + nt # corresponds to Sato Eq (3.89) / dの全てのkに対して一度にしている\n",
    "                                        # nt:  probably expectation part in Sato Equation(3.89)\n",
    "        xi_kv = n_kv + beta.T  # Sato (3.95)\n",
    "        return alpha, q, nt, n_kv, xi_kv\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def fpi_alpha(alpha, nt_keep):\n",
    "        # fixed point iteration for alpha / Sato p.112\n",
    "        K = alpha.shape[0]\n",
    "        M = len(nt_keep)\n",
    "        digamma = lambda x: polygamma(0,x)\n",
    "\n",
    "        for k in range(K):\n",
    "            alpha_k = alpha[k, 0]\n",
    "\n",
    "            numerator = 0 ; denominator = 0\n",
    "            for m in range(M):\n",
    "                nt = nt_keep[m]\n",
    "                nd = nt.sum() # Sato p.114\n",
    "\n",
    "                # numerator\n",
    "                numerator += (digamma(nt[k,0] + alpha_k) - digamma(alpha_k)) * alpha_k\n",
    "\n",
    "                # denominator\n",
    "                denominator += digamma(nd + alpha.sum()) - digamma(alpha.sum())\n",
    "\n",
    "            alpha[k,0] = numerator / denominator\n",
    "\n",
    "        return alpha\n",
    "    \n",
    "    @staticmethod\n",
    "    def fpi_beta1(n_kv, beta):\n",
    "        K, V = n_kv.shape\n",
    "        new_beta = matrix(zeros((V, 1)))\n",
    "        digamma = lambda x: polygamma(0,x)\n",
    "\n",
    "        for v in range(V):\n",
    "            numerator = 0 ; denominator = 0\n",
    "            for k in range(K):\n",
    "                numerator += (digamma(n_kv[k, v] + beta[v, 0]) - digamma(beta[v, 0])) * beta[v, 0]\n",
    "                denominator += (digamma(n_kv[k, :].sum() + beta[v,0]) - digamma(beta.sum()))\n",
    "\n",
    "            new_beta[v, :]  = numerator / denominator\n",
    "            \n",
    "        return lda.normalize(new_beta)\n",
    "    \n",
    "    @staticmethod\n",
    "    def fpi_beta2(n_kv, beta): # Sato (3.194)\n",
    "        K, V = n_kv.shape\n",
    "        new_beta = matrix(zeros((V, 1)))\n",
    "        digamma = lambda x: polygamma(0,x) \n",
    "\n",
    "        component1 = 0\n",
    "        for k in range(K):\n",
    "            for v in range(V):\n",
    "                component1 += n_kv[k,v]\n",
    "\n",
    "        numerator = 0\n",
    "        for v in range(V):\n",
    "            for k in range(K):\n",
    "                numerator += (digamma(n_kv[k,v] + beta[0,0]) - digamma(beta[0,0])) * beta[0,0]\n",
    "\n",
    "        denominator = 0\n",
    "        for k in range(K):\n",
    "            denominator += digamma(component1 + beta[0,0]) - digamma(V * beta[0,0])\n",
    "\n",
    "        new_beta.fill(numerator / denominator / V)\n",
    "        return lda.normalize(new_beta)\n",
    "\n",
    "    @staticmethod\n",
    "    def accum_phi(phis, q, di, xi_kv):\n",
    "        '''\n",
    "        phis = accum_phi(phis,q,t)\n",
    "        accumulates word posteriors to latent classes.\n",
    "        phis : (V * K) matrix of summand\n",
    "        q     : (L * K) matrix of word posteriors\n",
    "        t     : document of struct array\n",
    "        '''\n",
    "        new_phis  = matrix(zeros((phis.shape[0], phis.shape[1])))\n",
    "        #for k in range(phis.shape[0]):\n",
    "        for k in range(phis.shape[0]):\n",
    "            new_phis[k, :] = matrix(np.random.dirichlet(np.squeeze(np.asarray(xi_kv[k,:])) , 1))\n",
    "\n",
    "            #new_phis[k, :] =  lda.normalize(new_phis[k, :])\n",
    "        \n",
    "        return new_phis\n",
    "    \n",
    "    @staticmethod\n",
    "    def lda_lik(d, phi, gammas):\n",
    "        '''\n",
    "        lik = lda_lik(d, phi, gammas)\n",
    "        returns the likelihood of d, given LDA model of (phi, gammas).\n",
    "        '''\n",
    "        egamma = matrix(lda.mnormalize(gammas, 1))\n",
    "        lik = 0\n",
    "        M = len(d)\n",
    "        for i in range(M):\n",
    "            t = d[i]\n",
    "            lik += (matrix(t[1]) * log(matrix(phi[:,t[0]]).T * egamma[i,:].T))[0,0]\n",
    "        return lik\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(v):\n",
    "        return v / sum(v)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mnormalize(m, d=0):\n",
    "        '''\n",
    "        x = mnormalize(m, d)\n",
    "        normalizes a 2-D matrix m along the dimension d.\n",
    "        m : matrix\n",
    "        d : dimension to normalize (default 0)\n",
    "        '''\n",
    "        m = array(m)\n",
    "        v = sum(m, d)\n",
    "        if d == 0:\n",
    "            return m * matrix(diag(1.0 / v))\n",
    "        else:\n",
    "            return matrix(diag(1.0 / v)) * m\n",
    "        \n",
    "    @staticmethod\n",
    "    def converged(u, udash, threshold=1.0e-3):\n",
    "        '''\n",
    "        converged(u,udash,threshold)\n",
    "        Returns 1 if u and udash are not different by the ratio threshold\n",
    "        '''\n",
    "        return norm(u - udash) / norm(u) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1/100..\t\n",
      "iteration 11/100..\t\n",
      "iteration 21/100..\t\n",
      "iteration 31/100..\t\n",
      "iteration 41/100..\t\n",
      "iteration 51/100..\t\n",
      "iteration 61/100..\t\n",
      "iteration 71/100..\t\n",
      "iteration 81/100..\t\n",
      "iteration 91/100..\t\n",
      "Topic:  0\n",
      "1112    0.021716\n",
      "1048    0.019001\n",
      "1173    0.017962\n",
      "911     0.015271\n",
      "237     0.014695\n",
      "1109    0.013554\n",
      "531     0.013316\n",
      "1102    0.013093\n",
      "559     0.011188\n",
      "270     0.011043\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  1\n",
      "5       0.245890\n",
      "381     0.112261\n",
      "1234    0.083534\n",
      "806     0.067471\n",
      "143     0.066197\n",
      "190     0.061913\n",
      "518     0.059160\n",
      "609     0.049380\n",
      "819     0.047880\n",
      "951     0.039718\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  2\n",
      "675     0.020342\n",
      "753     0.017355\n",
      "1104    0.015371\n",
      "1226    0.013913\n",
      "151     0.012824\n",
      "739     0.012513\n",
      "604     0.012169\n",
      "672     0.011331\n",
      "423     0.011158\n",
      "395     0.010964\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  3\n",
      "382     0.028459\n",
      "49      0.023547\n",
      "571     0.022996\n",
      "439     0.022825\n",
      "17      0.020768\n",
      "1229    0.020237\n",
      "1227    0.019592\n",
      "397     0.018953\n",
      "177     0.018717\n",
      "637     0.016164\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  4\n",
      "1243    0.325477\n",
      "1135    0.163305\n",
      "1066    0.155819\n",
      "1129    0.093897\n",
      "393     0.068980\n",
      "702     0.057142\n",
      "1323    0.052908\n",
      "1003    0.031331\n",
      "1       0.021752\n",
      "1161    0.019112\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  5\n",
      "41      0.489998\n",
      "1262    0.158108\n",
      "638     0.086243\n",
      "1069    0.080845\n",
      "1       0.049129\n",
      "13      0.042782\n",
      "907     0.040342\n",
      "1148    0.024778\n",
      "139     0.009528\n",
      "156     0.009069\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  6\n",
      "1052    0.046350\n",
      "676     0.045528\n",
      "657     0.045133\n",
      "1035    0.042452\n",
      "285     0.041061\n",
      "519     0.039969\n",
      "1256    0.037967\n",
      "612     0.033984\n",
      "1015    0.033257\n",
      "180     0.028676\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  7\n",
      "598     0.103409\n",
      "1267    0.094712\n",
      "482     0.090544\n",
      "750     0.073397\n",
      "495     0.066883\n",
      "345     0.056081\n",
      "251     0.042232\n",
      "174     0.041775\n",
      "1294    0.040242\n",
      "615     0.038616\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  8\n",
      "135     0.014434\n",
      "51      0.013969\n",
      "534     0.013537\n",
      "213     0.012839\n",
      "924     0.011534\n",
      "1324    0.009822\n",
      "580     0.009637\n",
      "1004    0.009483\n",
      "358     0.009213\n",
      "219     0.009131\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  9\n",
      "282     0.349643\n",
      "172     0.306681\n",
      "1115    0.150597\n",
      "227     0.075633\n",
      "1309    0.040807\n",
      "1300    0.038295\n",
      "126     0.015406\n",
      "1110    0.011266\n",
      "815     0.004954\n",
      "1123    0.003209\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    alpha, phi, beta = main(emmax=100, beta_estimate = 0)\n",
    "    \n",
    "    res_b = pd.DataFrame(phi)\n",
    "    for i in range(phi.shape[0]):\n",
    "        res_temp = res_b.ix[i, :].sort_values(ascending=False)[:10]\n",
    "        res_temp.index += 1\n",
    "        print(\"Topic: \", i)\n",
    "        print(res_temp)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1325)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 21.26906388],\n",
       "        [  1.47223864],\n",
       "        [ 24.86255934],\n",
       "        [ 13.89003648],\n",
       "        [  0.97423875],\n",
       "        [  0.60042885],\n",
       "        [  7.16496515],\n",
       "        [  2.38684358],\n",
       "        [ 30.29829766],\n",
       "        [  0.24363894]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.00075472],\n",
       "        [ 0.00075472],\n",
       "        [ 0.00075472],\n",
       "        ..., \n",
       "        [ 0.00075472],\n",
       "        [ 0.00075472],\n",
       "        [ 0.00075472]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1/100..\t\n",
      "iteration 11/100..\t\n",
      "iteration 21/100..\t\n",
      "iteration 31/100..\t\n",
      "iteration 41/100..\t\n",
      "iteration 51/100..\t\n",
      "iteration 61/100..\t\n",
      "iteration 71/100..\t\n",
      "iteration 81/100..\t\n",
      "iteration 91/100..\t\n",
      "Topic:  0\n",
      "1022    0.084285\n",
      "1204    0.066847\n",
      "434     0.060068\n",
      "1179    0.057567\n",
      "84      0.050714\n",
      "594     0.042551\n",
      "174     0.034533\n",
      "897     0.033883\n",
      "1282    0.033361\n",
      "471     0.032694\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  1\n",
      "733     0.038713\n",
      "599     0.020153\n",
      "812     0.017665\n",
      "1183    0.017340\n",
      "1148    0.017062\n",
      "28      0.016312\n",
      "580     0.016175\n",
      "1086    0.016045\n",
      "758     0.015622\n",
      "861     0.015400\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  2\n",
      "191     0.069972\n",
      "1143    0.059398\n",
      "212     0.057721\n",
      "764     0.053048\n",
      "985     0.050190\n",
      "1227    0.041930\n",
      "950     0.037553\n",
      "1184    0.036363\n",
      "914     0.034358\n",
      "1251    0.032594\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  3\n",
      "233     0.023951\n",
      "1004    0.022567\n",
      "659     0.018643\n",
      "562     0.013913\n",
      "1319    0.011591\n",
      "831     0.011274\n",
      "595     0.009904\n",
      "246     0.009428\n",
      "224     0.008658\n",
      "203     0.008365\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  4\n",
      "207     0.381368\n",
      "1190    0.152587\n",
      "1       0.130331\n",
      "809     0.120453\n",
      "849     0.109696\n",
      "686     0.027869\n",
      "588     0.020513\n",
      "1286    0.016671\n",
      "521     0.012799\n",
      "171     0.009979\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  5\n",
      "448     0.098995\n",
      "457     0.098552\n",
      "1081    0.062757\n",
      "106     0.054161\n",
      "280     0.052905\n",
      "321     0.049081\n",
      "306     0.040421\n",
      "902     0.036608\n",
      "510     0.036129\n",
      "1207    0.035273\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  6\n",
      "540     0.020236\n",
      "395     0.016247\n",
      "222     0.015208\n",
      "447     0.012139\n",
      "1077    0.012060\n",
      "1182    0.011078\n",
      "229     0.010859\n",
      "485     0.010806\n",
      "751     0.010367\n",
      "937     0.010246\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  7\n",
      "135     0.033455\n",
      "19      0.032620\n",
      "1080    0.032258\n",
      "1242    0.030721\n",
      "654     0.029465\n",
      "363     0.025822\n",
      "725     0.022668\n",
      "1108    0.021923\n",
      "1264    0.020985\n",
      "555     0.020928\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  8\n",
      "115     0.092389\n",
      "786     0.083551\n",
      "377     0.069765\n",
      "1278    0.067165\n",
      "266     0.067064\n",
      "286     0.063344\n",
      "801     0.046033\n",
      "1298    0.043822\n",
      "798     0.040145\n",
      "1152    0.039258\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "Topic:  9\n",
      "1036    0.468933\n",
      "1222    0.196075\n",
      "1       0.166729\n",
      "199     0.131328\n",
      "638     0.024667\n",
      "500     0.010035\n",
      "1208    0.000747\n",
      "1004    0.000614\n",
      "731     0.000553\n",
      "287     0.000276\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha, phi, beta = main(emmax=100, beta_estimate = 1)\n",
    "\n",
    "res_b = pd.DataFrame(phi)\n",
    "for i in range(phi.shape[0]):\n",
    "    res_temp = res_b.ix[i, :].sort_values(ascending=False)[:10]\n",
    "    res_temp.index += 1\n",
    "    print(\"Topic: \", i)\n",
    "    print(res_temp)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
